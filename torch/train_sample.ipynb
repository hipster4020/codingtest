{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_sample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzjUr4rf5zBG2ldNjqOr1b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hipster4020/training/blob/master/torch/train_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkEN758jxwR4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(nn.Module):\n",
        "    \"\"\"\n",
        "    퍼셉트론은 하나의 선형층\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            input_dim(int): 입력 특성 크기 \n",
        "        \"\"\"\n",
        "        super(Perceptron, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 1) # weight, bias는 nn.Linear에서 관리. 절편이 필요없다면 nn.Linear 호출 시 bias=False\n",
        "        \n",
        "    def forward(self, x_in):\n",
        "        \"\"\"\n",
        "        퍼셉트론의 정방향 계산\n",
        "        \n",
        "        parameter:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서\n",
        "                x_in.shape는 (batch, num_features)입니다.\n",
        "        return:\n",
        "            결과 텐서. tensor.shape는 (batch,)입니다.\n",
        "        \"\"\"\n",
        "        return torch.sigmoid(self.fc1(x_in)).squeeze()"
      ],
      "metadata": {
        "id": "BpmQKYWXzGlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam\n",
        "input_dim = 2\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "w1dpvCHGyQHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perceptron = Perceptron(input_dim=input_dim)\n",
        "bce_loss = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=perceptron.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "gRS23Z2lyS2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "n_epochs = 10\n",
        "n_batches = 10"
      ],
      "metadata": {
        "id": "dep60_Y01COP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train data\n",
        "for epoch_i in range(n_epochs):\n",
        "  # dataset batch\n",
        "  for batch_i in range(n_batches):\n",
        "    # 1. data load\n",
        "    x_data, y_target = get_toy_data(batch_size)\n",
        "\n",
        "    # 2. gradient init\n",
        "    perceptron.zero_grad()\n",
        "\n",
        "    # 3. 모델 정방향 계산\n",
        "    y_pred = perceptron(x_data, apply_sigmoid=True)\n",
        "\n",
        "    # 4. 최적하려는 손실 계산\n",
        "    loss = bce_loss(y_pred, y_target)\n",
        "\n",
        "    # 5. 손실 신호 역전파\n",
        "    loss.backward()\n",
        "\n",
        "    # 6. 옵티마이저 업데이트\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "gCl3FbRR1Lef"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}